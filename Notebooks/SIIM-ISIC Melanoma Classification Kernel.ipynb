{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install image-classifiers > /dev/null","execution_count":1,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport pydicom\nimport warnings\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport multiprocessing\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook as tqdm\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Sequential\nfrom classification_models.tfkeras import Classifiers\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM, CuDNNGRU\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold,KFold, GroupKFold\nfrom tensorflow.keras.applications import InceptionResNetV2,InceptionV3, ResNet50\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D,GlobalAveragePooling2D","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\nplt.rcParams['figure.figsize'] = (10,5)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CORES = multiprocessing.cpu_count()\nSPLITS = 5\nINPUT_PATH = './../input/siim-isic-melanoma-classification'\nSUB_PATH = './../../working/'\nDIM = (128,128)\nAUTO = tf.data.experimental.AUTOTUNE\nBATCH = 16\nEPOCHS = 10\nCNN_ARCH = 'resnet50'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self,df,image_path,batch_size,dim,n_channels,to_fit):\n      self.df = df\n      self.image_path = image_path\n      self.batch = batch_size\n      self.dim = dim\n      self.n_channels = n_channels\n      self.to_fit = to_fit\n      \n    def __len__(self):\n      return int(np.floor(self.df.shape[0])/self.batch)\n    \n    def __getitem__(self, index):\n      list_IDs = self.df['image_name'].values[index*self.batch : (index+1)*self.batch]\n      X = self._generate_X(list_IDs)\n      if self.to_fit:\n          target_y = self._generate_y(list_IDs)\n          return np.array(X), np.array(target_y)\n      return np.array(X)\n    \n    def _generate_X(self,list_IDs):\n      X = Parallel(n_jobs=self.batch)(delayed(self._load_image)(i) for i in list_IDs)\n      return X\n    \n    def _generate_y(self,list_IDs):\n      target_y = []\n      for i, ids in enumerate(list_IDs):\n          target_y.append(self.df[self.df['image_name'] == ids]['target'].values[0])\n      return target_y\n    \n    def _load_image(self,file_):\n      img = cv2.imread(os.path.join(self.image_path,file_)+'.jpg')\n      return img","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale(type_,data):\n    assert type_ in ['norm','std']\n    if type_ == 'std':\n        return (data - np.mean(data))/np.std(data)\n    elif type_ == 'norm':\n        return (data - np.min(data))/(np.max(data) - np.min(data))\n    \n    \ndef corrcted_age_from_dcm(folder,file):\n    return pydicom.dcmread(f'{folder}/{file}.dcm')[('0010', '1010')][1:3]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show(folder,file_name,gray=False):\n    img = cv2.imread(f'jpeg/{folder}/{file_name}.jpg')\n    if gray:\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n        print(f'Shape of Gray Image : {img.shape}')\n    else:\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        print(f'Shape of RGB Image : {img.shape}')\n    _=plt.imshow(img)\n    _=plt.xticks([])\n    _=plt.yticks([])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def color_constancy(img, power=6, gamma=None):\n    img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n    img_dtype = img.dtype\n\n    if gamma is not None:\n        img = img.astype('uint8')\n        look_up_table = np.ones((256,1), dtype='uint8') * 0\n        for i in range(256):\n            look_up_table[i][0] = 255*pow(i/255, 1/gamma)\n        img = cv2.LUT(img, look_up_table)\n\n    img = img.astype('float32')\n    img_power = np.power(img, power)\n    rgb_vec = np.power(np.mean(img_power, (0,1)), 1/power)\n    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n    rgb_vec = rgb_vec/rgb_norm\n    rgb_vec = 1/(rgb_vec*np.sqrt(3))\n    img = np.multiply(img, rgb_vec)\n\n    img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n    return img.astype(img_dtype)\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_jpeg(filename,label=None,size=(128,128)):\n    if label is None:\n        path = './../melanoma-128x128-jpeg/128x128/Test/'\n    else:\n        path = './../melanoma-128x128-jpeg/128x128/Train/'\n    file_path = path + filename\n    bits = tf.io.read_file(file_path)\n    img = tf.image.decode_image(bits,channels=3)\n    img = tf.stack((img[:,:,2],img[:,:,1],img[:,:,0]),axis=2)\n    img = tf.cast(img,tf.float32)/255.0\n    #img = tf.image.resize(img,size=size)\n    if label is None:\n        return img\n    else:\n        return img,label\n    \n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_fold_data(fold):\n    train_fold = (tf.data.Dataset\n                    .from_tensor_slices((train[train['stratified_folds'] != fold]['image_name'],\n                                         train[train['stratified_folds'] != fold]['target']))\n                    .map(decode_jpeg,num_parallel_calls=AUTO)\n                    .map(data_augment, num_parallel_calls=AUTO)\n                    .repeat()\n                    .batch(BATCH)\n                    .prefetch(AUTO))\n    valid_fold = (tf.data.Dataset\n                    .from_tensor_slices((train[train['stratified_folds'] == fold]['image_name'],\n                                         train[train['stratified_folds'] == fold]['target']))\n                    .map(decode_jpeg,num_parallel_calls=AUTO)\n                    .map(data_augment, num_parallel_calls=AUTO)\n                    .repeat()\n                    .batch(BATCH)\n                    .prefetch(AUTO))\n    return train_fold,valid_fold","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    ResNet18, preprocess_input = Classifiers.get('resnet18')\n    base_model = ResNet18(input_shape=(*DIM,3), weights='imagenet', include_top=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(inputs=[base_model.input], outputs=[output])  \n    return model","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir(INPUT_PATH)\nos.listdir()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"['test.csv',\n 'train',\n 'jpeg',\n 'sample_submission.csv',\n 'train.csv',\n 'tfrecords',\n 'test']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('./../markings/marking.csv')\ntrain['image_id'] = train['image_id'] + '.jpg'\n\ndir_files = os.listdir('./../melanoma-128x128-jpeg/128x128/Train')\ncsv_files = train['image_id'].values\n\nq = list(set(dir_files).intersection(set(csv_files)))\ntrain = train.loc[train.image_id.isin(q)]\n\ntrain['image_id'] = train['image_id'].apply(lambda x:x.split('.')[0])\n\ntrain = train.rename(columns={'patient_id':'p_id',\n                             'age_approx':'age',\n                             'anatom_site_general_challenge':'site',\n                             'image_id':'image_name'})\n\ntrain = train.sort_values(by=['p_id','site','age'])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('./../melanoma-age-corrected-dataset/test.csv')\nsubmission = pd.read_csv('sample_submission.csv')\nuse_cols = test.columns.tolist() + ['target']\ntrain = train[use_cols]\n\ntrain['image_name'] = train['image_name'] + '.jpg'\ntest['image_name'] = test['image_name'] + '.jpg'\nsubmission['image_name'] = submission['image_name'] + '.jpg'","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=SPLITS)\ntrain['stratified_folds'] = -1\nfor i, (_,val_idx) in enumerate(folds.split(X = train,y = train['target'])):\n    train.loc[train.index.isin(val_idx),'stratified_folds'] = i\n\nfolds_value = []\nfor i in range(SPLITS):\n    distribution = []\n    distribution.append(i)\n    distribution.append(train[(train['stratified_folds'] == i) & (train['target'] == 1)].shape[0]/train.shape[0])\n    distribution.append(train[(train['stratified_folds'] == i) & (train['target'] == 0)].shape[0]/train.shape[0])\n    folds_value.append(distribution)\n\npd.DataFrame(folds_value,columns=['stratified_folds','positive_distribution','negative_distribution'])","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"   stratified_folds  positive_distribution  negative_distribution\n0                 0               0.003253               0.196754\n1                 1               0.003629               0.196378\n2                 2               0.005975               0.159091\n3                 3               0.023026               0.176964\n4                 4               0.044956               0.154469","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stratified_folds</th>\n      <th>positive_distribution</th>\n      <th>negative_distribution</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.003253</td>\n      <td>0.196754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.003629</td>\n      <td>0.196378</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.005975</td>\n      <td>0.159091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.023026</td>\n      <td>0.176964</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.044956</td>\n      <td>0.154469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = np.linspace(0,SPLITS-1,SPLITS)\nfor i in folds:\n    print(f'FOR FOLD {i}')\n    for j in [x for x in folds if x not in [i]]:\n        num_overlap = len(set(train[train['stratified_folds'] == i]['p_id'].values).\\\n                          intersection(set(train[train['stratified_folds'] == j]['p_id'].values)))\n        if num_overlap > 0: \n            print(f'Overlapped Patient ids in stratified fold {j} is {num_overlap}')\n    print('=============================================================')","execution_count":16,"outputs":[{"output_type":"stream","text":"FOR FOLD 0.0\nOverlapped Patient ids in stratified fold 1.0 is 1782\nOverlapped Patient ids in stratified fold 2.0 is 1672\nOverlapped Patient ids in stratified fold 3.0 is 648\nOverlapped Patient ids in stratified fold 4.0 is 53\n=============================================================\nFOR FOLD 1.0\nOverlapped Patient ids in stratified fold 0.0 is 1782\nOverlapped Patient ids in stratified fold 2.0 is 1669\nOverlapped Patient ids in stratified fold 3.0 is 653\nOverlapped Patient ids in stratified fold 4.0 is 54\n=============================================================\nFOR FOLD 2.0\nOverlapped Patient ids in stratified fold 0.0 is 1672\nOverlapped Patient ids in stratified fold 1.0 is 1669\nOverlapped Patient ids in stratified fold 3.0 is 686\nOverlapped Patient ids in stratified fold 4.0 is 52\n=============================================================\nFOR FOLD 3.0\nOverlapped Patient ids in stratified fold 0.0 is 648\nOverlapped Patient ids in stratified fold 1.0 is 653\nOverlapped Patient ids in stratified fold 2.0 is 686\nOverlapped Patient ids in stratified fold 4.0 is 867\n=============================================================\nFOR FOLD 4.0\nOverlapped Patient ids in stratified fold 0.0 is 53\nOverlapped Patient ids in stratified fold 1.0 is 54\nOverlapped Patient ids in stratified fold 2.0 is 52\nOverlapped Patient ids in stratified fold 3.0 is 867\n=============================================================\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"GPU = True \nTPU = False \nif(GPU):\n  print('Setting GPU')\n  K.clear_session()\n  config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n  graph = tf.compat.v1.get_default_graph()\n  sess = tf.compat.v1.Session(graph=graph,config=config)\n  tf.compat.v1.keras.backend.set_session(sess)\nelif((not GPU) or (TPU)):\n  print('Setting TPU')\n  try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\n  except ValueError:\n      tpu = None\n\n  if tpu:\n      tf.config.experimental_connect_to_cluster(tpu)\n      tf.tpu.experimental.initialize_tpu_system(tpu)\n      strategy = tf.distribute.experimental.TPUStrategy(tpu)\n  else:\n      strategy = tf.distribute.get_strategy()\n\n  print(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":24,"outputs":[{"output_type":"stream","text":"Setting GPU\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_fold_0,valid_data_fold_0 = get_fold_data(0)\ntrain_data_fold_1,valid_data_fold_1 = get_fold_data(1)\ntrain_data_fold_2,valid_data_fold_2 = get_fold_data(2)\ntrain_data_fold_3,valid_data_fold_3 = get_fold_data(3)\ntrain_data_fold_4,valid_data_fold_4 = get_fold_data(4)\n\ntest_data = (tf.data.Dataset\n            .from_tensor_slices(submission['image_name'])\n            .map(decode_jpeg,num_parallel_calls=AUTO)\n            .map(data_augment, num_parallel_calls=AUTO)\n            .batch(BATCH)\n            .prefetch(AUTO))\ngc.collect()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"22"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_checkpoint = ModelCheckpoint(filepath='./../../working/ResNet18_weights.{epoch:02d}.hdf5',\n                                   monitor='val_auc',verbose=1,save_best_only=True,\n                                   save_weights_only=True,mode='max')\nlr_schedule = ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3,min_lr=0.000008)\n\nSTEPS_PER_EPOCH = train[train['stratified_folds'] != 1].shape[0]//BATCH\nSTEPS_PER_EPOCH_VALID = train[train['stratified_folds'] == 1].shape[0]//BATCH","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fold_0 = get_model()\nmodel_fold_0.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=0.000025),\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhistory_0 = model_fold_0.fit(train_data_fold_0,\n                epochs=10,\n                callbacks=[model_checkpoint,lr_schedule],\n                validation_data=valid_data_fold_0,\n                steps_per_epoch=STEPS_PER_EPOCH,\n                validation_steps=STEPS_PER_EPOCH_VALID)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_fold_0 = model_fold_0.predict(test_data,verbose = 1)\nsubmission['pred_fold_0'] = probs_fold_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fold_1 = get_model()\nmodel_fold_1.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=0.000025),\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhistory_1 = model_fold_0.fit(train_data_fold_1,\n                epochs=10,\n                callbacks=[model_checkpoint,lr_schedule],\n                validation_data=valid_data_fold_1,\n                steps_per_epoch=STEPS_PER_EPOCH,\n                validation_steps=STEPS_PER_EPOCH_VALID)","execution_count":47,"outputs":[{"output_type":"stream","text":"Train for 2920 steps, validate for 730 steps\nEpoch 1/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9517 - auc: 0.9439\nEpoch 00001: val_auc improved from 0.76777 to 0.89187, saving model to ./../../working/ResNet18_weights.01.hdf5\n2920/2920 [==============================] - 105s 36ms/step - loss: 0.1506 - accuracy: 0.9513 - auc: 0.9437 - val_loss: 0.0843 - val_accuracy: 0.9850 - val_auc: 0.8919\nEpoch 2/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9518 - auc: 0.9484\nEpoch 00002: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 123s 42ms/step - loss: 0.1470 - accuracy: 0.9516 - auc: 0.9484 - val_loss: 0.0953 - val_accuracy: 0.9767 - val_auc: 0.8909\nEpoch 3/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9527 - auc: 0.9549\nEpoch 00003: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 103s 35ms/step - loss: 0.1384 - accuracy: 0.9527 - auc: 0.9549 - val_loss: 0.1154 - val_accuracy: 0.9745 - val_auc: 0.8846\nEpoch 4/10\n2918/2920 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9585 - auc: 0.9638\nEpoch 00004: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 102s 35ms/step - loss: 0.1255 - accuracy: 0.9585 - auc: 0.9638 - val_loss: 0.1250 - val_accuracy: 0.9705 - val_auc: 0.8520\nEpoch 5/10\n2918/2920 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9593 - auc: 0.9668\nEpoch 00005: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 101s 35ms/step - loss: 0.1223 - accuracy: 0.9593 - auc: 0.9668 - val_loss: 0.1152 - val_accuracy: 0.9729 - val_auc: 0.8598\nEpoch 6/10\n2918/2920 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9650 - auc: 0.9745\nEpoch 00006: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 100s 34ms/step - loss: 0.1089 - accuracy: 0.9650 - auc: 0.9745 - val_loss: 0.1172 - val_accuracy: 0.9729 - val_auc: 0.8726\nEpoch 7/10\n2918/2920 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9673 - auc: 0.9777\nEpoch 00007: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 101s 35ms/step - loss: 0.1014 - accuracy: 0.9673 - auc: 0.9777 - val_loss: 0.1343 - val_accuracy: 0.9633 - val_auc: 0.8595\nEpoch 8/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9679 - auc: 0.9813\nEpoch 00008: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 101s 35ms/step - loss: 0.0952 - accuracy: 0.9680 - auc: 0.9813 - val_loss: 0.1163 - val_accuracy: 0.9699 - val_auc: 0.8899\nEpoch 9/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9746 - auc: 0.9872\nEpoch 00009: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 100s 34ms/step - loss: 0.0810 - accuracy: 0.9746 - auc: 0.9872 - val_loss: 0.1056 - val_accuracy: 0.9751 - val_auc: 0.8864\nEpoch 10/10\n2919/2920 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9760 - auc: 0.9883\nEpoch 00010: val_auc did not improve from 0.89187\n2920/2920 [==============================] - 102s 35ms/step - loss: 0.0758 - accuracy: 0.9760 - auc: 0.9883 - val_loss: 0.2050 - val_accuracy: 0.9307 - val_auc: 0.8369\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_fold_1 = model_fold_1.predict(test_data,verbose = 1)\nsubmission['pred_fold_1'] = probs_fold_1","execution_count":48,"outputs":[{"output_type":"stream","text":"687/687 [==============================] - 13s 18ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fold_2 = get_model()\nmodel_fold_2.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=0.000025),\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhistory_2 = model_fold_0.fit(train_data_fold_2,\n                epochs=10,\n                callbacks=[model_checkpoint,lr_schedule],\n                validation_data=valid_data_fold_2,\n                steps_per_epoch=STEPS_PER_EPOCH,\n                validation_steps=STEPS_PER_EPOCH_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fold_3 = get_model()\nmodel_fold_3.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=0.000025),\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhistory_3 = model_fold_0.fit(train_data_fold_3,\n                epochs=10,\n                callbacks=[model_checkpoint,lr_schedule],\n                validation_data=valid_data_fold_3,\n                steps_per_epoch=STEPS_PER_EPOCH,\n                validation_steps=STEPS_PER_EPOCH_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fold_4 = get_model()\nmodel_fold_4.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=0.000025),\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhistory_4 = model_fold_0.fit(train_data_fold_4,\n                epochs=10,\n                callbacks=[model_checkpoint,lr_schedule],\n                validation_data=valid_data_fold_4,\n                steps_per_epoch=STEPS_PER_EPOCH,\n                validation_steps=STEPS_PER_EPOCH_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_fold_2 = model_fold_2.predict(test_data,verbose = 1)\nsubmission['pred_fold_2'] = probs_fold_2\n\nprobs_fold_3 = model_fold_3.predict(test_data,verbose = 1)\nsubmission['pred_fold_3'] = probs_fold_3\n\nprobs_fold_4 = model_fold_4.predict(test_data,verbose = 1)\nsubmission['pred_fold_4'] = probs_fold_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Garbage"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n\"\"\"#WaveNet Model\ndef WaveNetResidualConv1D(num_filters, kernel_size, stacked_layer):\n\n    def build_residual_block(l_input):\n        resid_input = l_input\n        for dilation_rate in [2**i for i in range(stacked_layer)]:\n            l_sigmoid_conv1d = Conv1D(\n              num_filters, kernel_size, dilation_rate=dilation_rate,\n              padding='same', activation='sigmoid')(l_input)\n            l_tanh_conv1d = Conv1D(\n             num_filters, kernel_size, dilation_rate=dilation_rate,\n             padding='same', activation='mish')(l_input)\n            l_input = Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n            l_input = Conv1D(num_filters, 1, padding='same')(l_input)\n            resid_input = Add()([resid_input ,l_input])\n        return resid_input\n    return build_residual_block\ndef Classifier(shape_):\n    num_filters_ = 16\n    kernel_size_ = 3\n    stacked_layers_ = [12, 8, 4, 1]\n    l_input = Input(shape=(shape_))\n    x = Conv1D(num_filters_, 1, padding='same')(l_input)\n    x = WaveNetResidualConv1D(num_filters_, kernel_size_, stacked_layers_[0])(x)\n    x = Conv1D(num_filters_*2, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*2, kernel_size_, stacked_layers_[1])(x)\n    x = Conv1D(num_filters_*4, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*4, kernel_size_, stacked_layers_[2])(x)\n    x = Conv1D(num_filters_*8, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*8, kernel_size_, stacked_layers_[3])(x)\n    l_output = Dense(1, activation='linear')(x)\n    model = models.Model(inputs=[l_input], outputs=[l_output])\n    opt = Adam(lr=LR)\n    opt = tfa.optimizers.SWA(opt)\n    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n    return model\"\"\"\n\n\"\"\"SIIM Pneumonia Prediction Image Aug\n    \n    albu.Compose([\n    albu.HorizontalFlip(),\n    albu.VerticalFlip()\n    albu.OneOf([\n        albu.RandomContrast(),\n        albu.RandomGamma(),\n        albu.RandomBrightness(),\n        ], p=0.3),\n    albu.OneOf([\n        albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        albu.GridDistortion(),\n        albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n        ], p=0.3),\n    albu.ShiftScaleRotate(),\n    albu.Resize(img_size,img_size,always_apply=True),\n    ])\n\n\"\"\"\n\n\"\"\"folds = GroupKFold(n_splits=SPLITS)\ntrain['group_folds'] = -1\nfor i, (_,val_idx) in enumerate(folds.split(X = train,y = train['target'],groups=train['p_id'])):\n    train.loc[train.index.isin(val_idx),'group_folds'] = i\n    \nfor i in range(SPLITS):\n    print(f'Fold {i}')\n    print(train[train['group_folds'] == i]['target'].value_counts())\n    print('===================')\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}